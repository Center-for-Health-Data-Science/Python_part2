{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Classification: Heart Failure Data"],"metadata":{"id":"LW4rkaPCleKc"}},{"cell_type":"markdown","source":["For this part of the project, you will create a classification model. In the first part, you will train a decision tree model, and in the second part (optional and advanced), you will train a support vector machine model.\n","\n","The dataset contains the medical records of 260 patients who experienced heart failure, collected during their follow-up period. Each patient profile includes 11 clinical features. For more information on these features, you can refer to the metadata [here](https://archive.ics.uci.edu/dataset/519/heart+failure+clinical+records)."],"metadata":{"id":"TR66Wi2AlwEG"}},{"cell_type":"markdown","source":["## Import modules"],"metadata":{"id":"hEKrnZwal4Wp"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import plotly.express as px\n","import random"],"metadata":{"id":"3sVSXba8lzyT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load data"],"metadata":{"id":"sCL22QvMl-DE"}},{"cell_type":"code","source":["link_to_file = \"https://raw.githubusercontent.com/Center-for-Health-Data-Science/Python_part2/main/data/project_work/heart_failure.csv\"\n","\n","# Load in the data\n"],"metadata":{"id":"av8kjoivl7yN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## EDA and data cleaning\n","\n","The first step with our data is Exploratory Data Analysis (EDA). Use these questions to guide your analysis:\n","\n","* Which features/explanatory variables are present? Are they numeric or categorical? Should they all be interpreted the same way? What do you want to use as the outcome variable?\n","* Are there missing values?\n","* Is there an index or ID you should remove?\n","* Create bar plots for the categorical variables and check if the categories are balanced.\n","* Create box plots and summary statistics for the numeric variables. Check their distributions and ranges. Are there outliers present?\n","* Remove data you think is unreliable or wrong."],"metadata":{"id":"UvkKYm8Hn8nJ"}},{"cell_type":"code","source":[],"metadata":{"id":"TmKaQStTn6Cf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wCL2hR3a_cOD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XJpsJYj2_cTR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"E47rVB6L_cXr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Correlations\n","Take a look at the correlation between the numeric features and the outcome variable. Which numeric features exhibit the highest correlation with the outcome variable?"],"metadata":{"id":"tGqBEhRBqQGO"}},{"cell_type":"code","source":["# Define the correlation matrix\n"],"metadata":{"id":"ygoBZIkEqQbk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the correlation matrix in a heatmap\n"],"metadata":{"id":"EY3zAYL5qgX8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prepare data for modelling\n","\n","As you have learned during the course, there are several steps you should take to prepare your data before training a model. Before you read the list below, take a moment to recall some of those steps.\n","\n","* Scale numeric values: Define the standard scaler object, then fit and transform the numeric values.\n","* Convert categorical features to the appropriate data type so Python can interpret them as categories. Do they need to be dummy coded?\n","* Identify the outcome variable and ensure it is of the correct data type for analysis.\n","* Split your data and outcome variable into training and test sets.\n"],"metadata":{"id":"8pzWUkL0pVw4"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n"],"metadata":{"id":"mEeSpgdNn6Mm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c_fXBQZPn6Qj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EEHUc3-Wn6Ts"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n"],"metadata":{"id":"4xX0Y0qd6_O7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PCA\n","\n","Make a PCA of the scaled numeric features to investigate the structure of the data.\n"],"metadata":{"id":"HKbZEbCdvGa4"}},{"cell_type":"code","source":[],"metadata":{"id":"-tuLw0ObpD61"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VQ6EwDgnpDty"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training the model\n","\n","Now it is time to train a decision tree model with your traning data. Set `max_leaf_nodes` to 6."],"metadata":{"id":"Ts9Wvv79q9S7"}},{"cell_type":"code","source":["# Define model\n","from sklearn.tree import DecisionTreeClassifier\n","\n","\n","# Fit model to training data\n","\n","\n","# Plot the tree (take a look at the exercises)\n","from sklearn.tree import plot_tree\n"],"metadata":{"id":"omJLylq8rD1B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FpMAablFrjIW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model evaluation\n","\n","To evaluate model performance, apply the trained decision tree model to the test data. Assess the predicted labels and compare them to the known true classes (alive or dead, if you have used death as the outcome variable)."],"metadata":{"id":"LC4BNfrKrj2K"}},{"cell_type":"code","source":["# Predict the outcome of X_test\n","y_pred ="],"metadata":{"id":"uyyPVM5trwO_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For a classification model, we can use the confusion matrix to assess model performance.\n","\n","<details>\n","<summary>Confusion matrix explained</summary>\n","\n","|               | Predicted Positive | Predicted Negative |\n","|---------------|---------------------|---------------------|\n","| **Actual Positive**   | True Positive (TP)       | False Negative (FN)      |\n","| **Actual Negative**   | False Positive (FP)      | True Negative (TN)       |\n","\n","\n","- **True Positive (TP)**: The number of actual positive cases correctly predicted as positive.\n","- **False Negative (FN)**: The number of actual positive cases incorrectly predicted as negative.\n","- **False Positive (FP)**: The number of actual negative cases incorrectly predicted as positive.\n","- **True Negative (TN)**: The number of actual negative cases correctly predicted as negative.\n","\n","\n","\n","\n","</details>"],"metadata":{"id":"pfEserPgr9WS"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","# Define confusion matrix\n"],"metadata":{"id":"lhz31dJsr52T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, we calculate the precision score which is the proportion of the predicted cases that are actually cases. Consider what a 'case' represents in this dataset and what the precision score signifies in this context.\n","\n","<details>\n","<summary>Hint</summary>\n","\n","The formular for the precision score is:\n","\n","$$\n","\\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n","$$\n","\n","\n","\n","In the context of this dataset, and if you used 'death' as your outcome variable, the precision score signifies how many of those predicted to be dead are actually dead.\n","\n","\n","\n","</details>"],"metadata":{"id":"3fOT5M1QsGqa"}},{"cell_type":"code","source":["from sklearn.metrics import precision_score\n","\n","# Define presision score\n"],"metadata":{"id":"rXCceopRsIka"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally, we will calculate the recall score, which is the proportion of actual cases that are predicted as cases. Again, consider what this represents in the context of this dataset.\n","\n","<details>\n","<summary>Hint</summary>\n","\n","The formula for recall score is:\n","\n","$$\n","\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n","$$\n","\n","In the context of this dataset, and if you used 'death' as your outcome variable, the recall score signifies the proportion of actual dead individuals that were predicted as dead by the model.\n","\n","</details>"],"metadata":{"id":"T_QBFr3usNLh"}},{"cell_type":"code","source":["from sklearn.metrics import recall_score\n","\n","# Define recall score\n"],"metadata":{"id":"LaIPqCnWsPBX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model interpretation\n","\n","Let's look at the feature importances of the model using the `feature_importences_` attribute. Which features are the most important for the model? How were these correlated to the outcome variable in the correlation matrix? Are the important features what you expect? Why might they not be? How could the model be improved?\n","\n","<details>\n","<summary>Hint</summary>\n","\n","The dataset contains only 260 observations, and the categorical variables are not completely balanced (which is acceptable). Training with a larger dataset would improve generalization and potentially enhance performance when predicting the test data.\n","\n","</details>"],"metadata":{"id":"vCVjhOzysbzu"}},{"cell_type":"code","source":[],"metadata":{"id":"SVtecXijse3C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Optional and advanced part: Support Vector Machine\n","\n","If you feel comfortable with the previous section and want an extra challenge, this section is for you!\n","\n","We are going to fit a model that you haven't encountered yet: the Support Vector Machine (SVM). Use Google (or your preferred search engine) to find out which module from scikit-learn you need to import to use this model."],"metadata":{"id":"8kO9FTq_sw2h"}},{"cell_type":"markdown","source":["## Training the model"],"metadata":{"id":"75UmfbftGov0"}},{"cell_type":"code","source":["# Import the model\n","from sklearn import XXX\n","\n","# Initialize the model with default settings\n","\n","\n","# Fit the model with your traing data (use the same training data as you trained the desision tree on, if you want to be able the performance of both models)\n"],"metadata":{"id":"MtHRO0LZsxj2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model evaluation\n","\n","Use the model to predict the outcome of X_test."],"metadata":{"id":"e5-YtePuFvjk"}},{"cell_type":"code","source":[],"metadata":{"id":"zC7SJxP2IfXF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Construct the confusion matrix."],"metadata":{"id":"3IBOaf8bIhn2"}},{"cell_type":"code","source":[],"metadata":{"id":"gJCB543uIhvo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculate the precision score. Do you remember what this indicates?"],"metadata":{"id":"OE4uwzzeIuIw"}},{"cell_type":"code","source":[],"metadata":{"id":"3Y1RHPPHI3fM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculate the recall score. Do you rememeber what this indicates?"],"metadata":{"id":"PFCmohkJI7fq"}},{"cell_type":"code","source":[],"metadata":{"id":"w0cq8Rh9I6x0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Discuss the model performance with the person next to you."],"metadata":{"id":"f3JImHhXk1OO"}},{"cell_type":"markdown","source":["## Model optimization\n","\n","For now, we have trained the support vector machine model using the default settings. First, let’s examine the parameters of the model we just created using the `get_params()` function.  What is the default value of the kernel parameter?"],"metadata":{"id":"tdFX242GJF1S"}},{"cell_type":"code","source":[],"metadata":{"id":"HFbeOJWjJ_oE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, let’s examine the possible arguments for the kernel parameter. To do this, we will use the `help()` function."],"metadata":{"id":"Bf-_7sMVKJhq"}},{"cell_type":"code","source":[],"metadata":{"id":"y0ST1dAVKInA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Choose one of the possible kernel arguments (other than the default) and run the model again. Evaluate how this model performs compared to the default settings."],"metadata":{"id":"Spkxnw72Lc27"}},{"cell_type":"code","source":[],"metadata":{"id":"Ks755vjgLcSH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You will need to run the model with all possible kernel arguments to determine which kernel performs best with your data. Exclude the 'precomputed' argument. Try to create a loop or a function to avoid repetitive code."],"metadata":{"id":"XjMtJt0BNQlA"}},{"cell_type":"code","source":[],"metadata":{"id":"xhKTG65RNQz7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Discuss with your group or the person next to you which kernel performed the best."],"metadata":{"id":"dWQ4ohTeNxyi"}},{"cell_type":"code","source":[],"metadata":{"id":"seM9XDsvN3dz"},"execution_count":null,"outputs":[]}]}